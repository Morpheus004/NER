{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the dataset ner_dataset.csv from https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./archive/ner_dataset.csv', encoding= 'unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the sentences are broken into tokens in the column 'Word'. The column 'sentence #' displays the sentence number once and then prints NaN till the next sentence begins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract mappings required for the neuralÂ network\n",
    "To train a neural network, we will use two mappings as given below. The neural network will only take integers as input. So lets convert all the unique tokens in the corpus to its respective index.\n",
    "- {token} to {token id}: address the row in embeddings matrix for the current token.\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>22712</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>32833</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>6038</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>23582</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>19558</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      Thousands  NNS   O     22712       16\n",
       "1          NaN             of   IN   O     32833       16\n",
       "2          NaN  demonstrators  NNS   O      6038       16\n",
       "3          NaN           have  VBP   O     23582       16\n",
       "4          NaN        marched  VBN   O     19558       16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform columns to extract sequential data\n",
    "Next, lets fill NaN in 'sentence #' column using method ffill in fillna. Thereafter groupby on the sentence column to get a list of tokens and tags for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #     True\n",
       "Word           True\n",
       "POS           False\n",
       "Tag           False\n",
       "Word_idx      False\n",
       "Tag_idx       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_19584\\450957418.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_fillna = data.fillna(method='ffill', axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[22712, 32833, 6038, 23582, 19558, 13631, 2128...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[31258, 775, 22676, 15913, 31158, 4550, 33501,...</td>\n",
       "      <td>[5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[30771, 11600, 32572, 24898, 3426, 8923, 15313...</td>\n",
       "      <td>[16, 16, 8, 16, 16, 16, 16, 16, 2, 16, 16, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[34797, 17432, 16834, 7186, 1875, 12516, 28168...</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[894, 22131, 34707, 32557, 19922, 11238, 16724...</td>\n",
       "      <td>[2, 16, 16, 0, 15, 16, 8, 16, 2, 16, 5, 16, 5,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "0      Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1     Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2    Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3   Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
       "4  Sentence: 10000  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...   \n",
       "2  [NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...   \n",
       "3     [PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]   \n",
       "4  [NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...   \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...   \n",
       "\n",
       "                                            Word_idx  \\\n",
       "0  [22712, 32833, 6038, 23582, 19558, 13631, 2128...   \n",
       "1  [31258, 775, 22676, 15913, 31158, 4550, 33501,...   \n",
       "2  [30771, 11600, 32572, 24898, 3426, 8923, 15313...   \n",
       "3  [34797, 17432, 16834, 7186, 1875, 12516, 28168...   \n",
       "4  [894, 22131, 34707, 32557, 19922, 11238, 16724...   \n",
       "\n",
       "                                             Tag_idx  \n",
       "0  [16, 16, 16, 16, 16, 16, 2, 16, 16, 16, 16, 16...  \n",
       "1  [5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16...  \n",
       "2  [16, 16, 8, 16, 16, 16, 16, 16, 2, 16, 16, 16,...  \n",
       "3       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]  \n",
       "4  [2, 16, 16, 0, 15, 16, 8, 16, 2, 16, 5, 16, 5,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence #'], as_index=False)[['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx']].agg(lambda x: list(x))\n",
    "\n",
    "data_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pad sequences and split the dataset into train,Â test\n",
    "Padding: The LSTM layers accept sequences of same length only. Therefore we will want to transform our list of token_sequences ('Word_idx') which is lists of integers into a matrix of shape (token_sequences, max_len). We can use any length as max_len. In this project we will be using length of the longest sequence as max_len. The sequences that are shorter than max_len are padded with a specified value at the end.\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 43163 \n",
      "test_tokens length: 4796 \n",
      "train_tags: 43163 \n",
      "test_tags: 4796\n"
     ]
    }
   ],
   "source": [
    "def get_pad_train_test_val(data_group, data):\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    \n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "    \n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    \n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    \n",
    "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntrain_tags:', len(train_tags),\n",
    "        '\\ntest_tags:', len(test_tags)\n",
    "    )\n",
    "    \n",
    "    return train_tokens, test_tokens, train_tags, test_tags\n",
    "\n",
    "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test_val(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "22676\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "716\t[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "18713\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "10742\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "24401\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "4550\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "21969\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "16088\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "6269\t[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "10050\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "6513\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "15913\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "12133\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "33331\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "32728\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "32056\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "9495\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "22688\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "22977\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "15313\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "27655\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "25203\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "4330\t[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "27014\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "15921\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "22893\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "35177\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for token, tag in zip(train_tokens[0], train_tags[0]):\n",
    "    print('%s\\t%s' % (token, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build ModelÂ Layout\n",
    "\n",
    "Lets go through the process of building a neural network model with lstm layers. Please compare the layers brief and model plot given below to get a better understanding of the layers, input and output dimensions. We are building a simple model with 4 layers.\n",
    "\n",
    "- **Layer 1â-âEmbedding layer**Â : We will feed the padded sequences of equal length (104) to the embedding layer. Once the network has been trained, each token will get transformed into a vector of n dimensions. We have chosen the n dimensions to be (64).Â \n",
    "\n",
    "\n",
    "These are the dimensions (?, 104, 64) plotted in the model plot for input layer and embedding layer. TheÂ ? or None in the dimension specifies batches, when it is None orÂ ? the model can take any batch size.\n",
    "\n",
    "- **Layer 2â-âBidirectional LSTM**Â : Bidirectional lstm takes a recurrent layer (e.g. the first LSTM layer) as an argument. This layer takes the output from the previous embedding layer (104, 64). It also allows you to specify the merge mode, that is how the forward and backward outputs should be combined before being passed on to the next layer. The default mode is to concatenate, where the outputs are concatenated together, providing double the number of outputs to the next layer, in our case its 128(64 * 2).\n",
    "\n",
    "\n",
    "The output dimension of the bidirectional lstm layer (?, 104, 128) becomes the input dimension of the next lstm layer.\n",
    "\n",
    "- **Layer 3â-âLSTM Layer**Â :Â An LSTM network is a recurrent neural network that has LSTM cell blocks in place of our standard neural network layers. These cells have various components called the input gate, the forget gate and the output gate.\n",
    "\n",
    "\n",
    "This layer takes the output dimension from the previous bidirectional lstm layer (?, 104, 128) and outputs (?, 104, 256)\n",
    "\n",
    "\n",
    "\n",
    "- **Layer 4â-âTimeDistributed  Layer**Â : We are dealing with Many to Many RNN Architecture where we expect output from every input sequence for example (a1 âb1, a2 âb2â¦ an âbn) where a and b are inputs and outputs of every sequence. The TimeDistributeDense layers allow you to apply Dense(fully-connected) operation across every output over every time-step. If you don't use this, you would only have one final output.\n",
    "\n",
    "\n",
    "\n",
    "This layer take the output dimension of the previous lstm layer (104, 256) and outputs the max sequence length (104) and max tags (17)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# import keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  35179 \n",
      "output_dim:  32 \n",
      "input_length:  104 \n",
      "n_tags:  17\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 32\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
    "\n",
    "    #Optimiser \n",
    "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                         </span>â<span style=\"font-weight: bold\"> Output Shape                </span>â<span style=\"font-weight: bold\">         Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              â ?                           â     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      â ?                           â     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        â ?                           â     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) â ?                           â     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              â ?                           â     \u001b[38;5;34m0\u001b[0m (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      â ?                           â     \u001b[38;5;34m0\u001b[0m (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        â ?                           â     \u001b[38;5;34m0\u001b[0m (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
       "â time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) â ?                           â     \u001b[38;5;34m0\u001b[0m (unbuilt) â\n",
       "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m      8\u001b[0m model_bilstm_lstm \u001b[38;5;241m=\u001b[39m get_bilstm_lstm_model()\n\u001b[1;32m----> 9\u001b[0m plot_model(model_bilstm_lstm)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:421\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, show_layer_activations, show_trainable, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_pydot():\n\u001b[0;32m    427\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor `plot_model` to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    for _ in range(25):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss\n",
    "model_bilstm_lstm = get_bilstm_lstm_model()\n",
    "plot_model(model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.6975 - loss: 2.1064 - val_accuracy: 0.9679 - val_loss: 0.3765\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9677 - loss: 0.4074 - val_accuracy: 0.9679 - val_loss: 0.3524\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9677 - loss: 0.3812 - val_accuracy: 0.9679 - val_loss: 0.3457\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9677 - loss: 0.3506 - val_accuracy: 0.9679 - val_loss: 0.3114\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.9678 - loss: 0.3358 - val_accuracy: 0.9680 - val_loss: 0.2881\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9678 - loss: 0.3152 - val_accuracy: 0.9681 - val_loss: 0.2970\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.3108 - val_accuracy: 0.9680 - val_loss: 0.2680\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.2926 - val_accuracy: 0.9680 - val_loss: 0.2580\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.2775 - val_accuracy: 0.9681 - val_loss: 0.2444\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.2642 - val_accuracy: 0.9683 - val_loss: 0.2201\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9681 - loss: 0.2259 - val_accuracy: 0.9683 - val_loss: 0.1730\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9681 - loss: 0.1998 - val_accuracy: 0.9684 - val_loss: 0.1709\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9680 - loss: 0.1949 - val_accuracy: 0.9684 - val_loss: 0.1632\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9568 - loss: 0.2217 - val_accuracy: 0.9445 - val_loss: 0.2519\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9467 - loss: 0.2560 - val_accuracy: 0.9679 - val_loss: 0.1861\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9667 - loss: 0.2084 - val_accuracy: 0.9680 - val_loss: 0.1672\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9677 - loss: 0.1910 - val_accuracy: 0.9680 - val_loss: 0.1607\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9678 - loss: 0.1843 - val_accuracy: 0.9680 - val_loss: 0.1619\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.1779 - val_accuracy: 0.9684 - val_loss: 0.1541\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9680 - loss: 0.1728 - val_accuracy: 0.9681 - val_loss: 0.1504\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9680 - loss: 0.1694 - val_accuracy: 0.9682 - val_loss: 0.1519\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9681 - loss: 0.1645 - val_accuracy: 0.9682 - val_loss: 0.1477\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.9682 - loss: 0.1596 - val_accuracy: 0.9684 - val_loss: 0.1409\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9682 - loss: 0.1558 - val_accuracy: 0.9684 - val_loss: 0.1393\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9682 - loss: 0.1509 - val_accuracy: 0.9684 - val_loss: 0.1368\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['with_add_lstm'])\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model started with 0.9169 accuracy ended. After running 25 epochs with 1000 batch size, the final accuracy was 0.9687. Please experiment the model with different batch sizes, dropout value, optimisers, metrics and layers to get better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at E:\\anaconda3\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m41 packages\u001b[0m \u001b[2min 2.36s\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m20 packages\u001b[0m \u001b[2min 3.98s\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1.75s\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m20 packages\u001b[0m \u001b[2min 1.00s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.11\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4 (from file:///C:/b/abs_c1ywpu18ar/croot/numpy_and_numpy_base_1708638681471/work/dist/numpy-1.26.4-cp312-cp312-win_amd64.whl)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.8.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at E:\\anaconda3\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 278ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 427ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 418ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 4.14s\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mh5py\u001b[0m\u001b[2m==3.11.0 (from file:///C:/b/abs_c4ha_1xv14/croot/h5py_1715094776210/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh5py\u001b[0m\u001b[2m==3.12.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.1.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --upgrade numpy h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'E:\\\\anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\linalg\\\\_umath_linalg.cp312-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.8 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/60.8 kB 525.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 544.1 kB/s eta 0:00:00\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/12.6 MB 9.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/12.6 MB 9.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.6 MB 9.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.6 MB 10.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.2/12.6 MB 10.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.2/12.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.6 MB 10.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.8/12.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.3/12.6 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.6 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.9/12.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.6 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.8/12.6 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.3/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.4/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.6/3.0 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.0/3.0 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.5/3.0 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.0/3.0 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/3.0 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/3.0 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, h5py\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 435.7 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/12.8 MB 871.5 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.3/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.8 MB 3.6 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.3/12.8 MB 5.3 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.2/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.7/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.7/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.7/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.1/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 7.6 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.8 MB 8.4 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.7/12.8 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.7/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.1/12.8 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp(\n",
    "    'Jim bought 300 shares of Acme Corp. in 2006. And producing an annotated block of text that \\\n",
    "    highlights the names of entities: [Jim]Person bought 300 shares of \\\n",
    "    [Acme Corp.]Organization in [2006]Time. In this example, a person name consisting \\\n",
    "    of one token, a two-token company name and a temporal expression have been detected \\\n",
    "    and classified.State-of-the-art NER systems for English produce near-human performance. \\\n",
    "    For example, the best system entering MUC-7 scored 93.39% of F-measure while human \\\n",
    "    annotators scored 97.60% and 96.95%.[1][2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim PERSON\n",
      "300 CARDINAL\n",
      "Acme Corp. ORG\n",
      "2006 DATE\n",
      "300 CARDINAL\n",
      "Acme Corp.]Organization WORK_OF_ART\n",
      "2006]Time DATE\n",
      "one CARDINAL\n",
      "two CARDINAL\n",
      "NER ORG\n",
      "English NORP\n",
      "MUC-7 ORG\n",
      "93.39% PERCENT\n",
      "97.60% PERCENT\n",
      "96.95%.[1][2 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for w in text.ents:\n",
    "    print(w.text, w.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jim\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Acme Corp.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2006\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". And producing an annotated block of text that     highlights the names of entities: [Jim]Person bought \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " shares of     [\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Acme Corp.]Organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " in [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2006]Time\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". In this example, a person name consisting     of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " token, a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-token company name and a temporal expression have been detected     and classified.State-of-the-art \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " systems for \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    English\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " produce near-human performance.     For example, the best system entering \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MUC-7\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " scored \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    93.39%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of F-measure while human     annotators scored \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    97.60%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    96.95%.[1][2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "]</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(text, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numerals that do not fall under another type'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('CARDINAL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
